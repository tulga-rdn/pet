{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load neighbors_convert.so: /home/chorna/pet-last-layer/src/neighbors_convert.so: cannot open shared object file: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "import ase.io\n",
    "from src.hypers import load_hypers_from_file\n",
    "from src.data_preparation import get_all_species\n",
    "from src.pet import PET, PETUtilityWrapper, PETMLIPWrapper\n",
    "import torch\n",
    "from src.molecule import MoleculeCPP, Molecule\n",
    "from matscipy.neighbours import neighbour_list as neighbor_list\n",
    "\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def prepare_test(\n",
    "    stucture_path,\n",
    "    r_cut,\n",
    "    n_gnn,\n",
    "    n_trans,\n",
    "    hypers_path=\"./default_hypers/default_hypers.yaml\",\n",
    "):\n",
    "    structure = ase.io.read(stucture_path, index=0)\n",
    "    hypers = load_hypers_from_file(hypers_path)\n",
    "\n",
    "    MLIP_SETTINGS = hypers.MLIP_SETTINGS\n",
    "    ARCHITECTURAL_HYPERS = hypers.ARCHITECTURAL_HYPERS\n",
    "    FITTING_SCHEME = hypers.FITTING_SCHEME\n",
    "\n",
    "    ARCHITECTURAL_HYPERS.D_OUTPUT = 1  # energy is a single scalar\n",
    "    ARCHITECTURAL_HYPERS.TARGET_TYPE = \"structural\"  # energy is structural property\n",
    "    ARCHITECTURAL_HYPERS.TARGET_AGGREGATION = (\n",
    "        \"sum\"  # energy is a sum of atomic energies\n",
    "    )\n",
    "    ARCHITECTURAL_HYPERS.R_CUT = r_cut\n",
    "    ARCHITECTURAL_HYPERS.N_TRANS_LAYERS = n_trans\n",
    "    ARCHITECTURAL_HYPERS.N_GNN_LAYERS = n_gnn\n",
    "    all_species = get_all_species([structure])\n",
    "\n",
    "    model = PET(ARCHITECTURAL_HYPERS, 0.0, len(all_species)).to(device)\n",
    "    model = PETUtilityWrapper(model, FITTING_SCHEME.GLOBAL_AUG)\n",
    "\n",
    "    model = PETMLIPWrapper(model, MLIP_SETTINGS.USE_ENERGIES, MLIP_SETTINGS.USE_FORCES)\n",
    "    return model, structure, all_species, ARCHITECTURAL_HYPERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph(structure, all_species, ARCHITECTURAL_HYPERS):\n",
    "    molecule = Molecule(\n",
    "        structure,\n",
    "        ARCHITECTURAL_HYPERS.R_CUT,\n",
    "        ARCHITECTURAL_HYPERS.USE_ADDITIONAL_SCALAR_ATTRIBUTES,\n",
    "        ARCHITECTURAL_HYPERS.USE_LONG_RANGE,\n",
    "        ARCHITECTURAL_HYPERS.K_CUT,\n",
    "        ARCHITECTURAL_HYPERS.N_TARGETS > 1,\n",
    "        ARCHITECTURAL_HYPERS.N_TARGETS,\n",
    "    )\n",
    "    if ARCHITECTURAL_HYPERS.USE_LONG_RANGE:\n",
    "        raise NotImplementedError(\n",
    "            \"Long range interactions are not supported in the SingleStructCalculator\"\n",
    "        )\n",
    "\n",
    "    graph = molecule.get_graph(molecule.get_max_num(), all_species, None)\n",
    "    graph.batch = torch.zeros(graph.num_nodes, dtype=torch.long, device=graph.x.device)\n",
    "    graph = graph.to(device)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_predictions_old_python(model, structure, all_species, ARCHITECTURAL_HYPERS):\n",
    "    molecule = Molecule(\n",
    "        structure,\n",
    "        ARCHITECTURAL_HYPERS.R_CUT,\n",
    "        ARCHITECTURAL_HYPERS.USE_ADDITIONAL_SCALAR_ATTRIBUTES,\n",
    "        ARCHITECTURAL_HYPERS.USE_LONG_RANGE,\n",
    "        ARCHITECTURAL_HYPERS.K_CUT,\n",
    "        ARCHITECTURAL_HYPERS.N_TARGETS > 1,\n",
    "        ARCHITECTURAL_HYPERS.N_TARGETS,\n",
    "    )\n",
    "    if ARCHITECTURAL_HYPERS.USE_LONG_RANGE:\n",
    "        raise NotImplementedError(\n",
    "            \"Long range interactions are not supported in the SingleStructCalculator\"\n",
    "        )\n",
    "\n",
    "    graph = molecule.get_graph(molecule.get_max_num(), all_species, None)\n",
    "    graph.batch = torch.zeros(graph.num_nodes, dtype=torch.long, device=graph.x.device)\n",
    "    graph = graph.to(device)\n",
    "\n",
    "    print(\"graph\", graph)\n",
    "    prediction_energy, prediction_forces = model(\n",
    "        graph, augmentation=False, create_graph=False\n",
    "    )\n",
    "\n",
    "    return prediction_energy, prediction_forces, graph\n",
    "\n",
    "\n",
    "def get_predictions_cpp(model, structure, all_species, ARCHITECTURAL_HYPERS):\n",
    "\n",
    "    molecule = MoleculeCPP(\n",
    "        structure,\n",
    "        ARCHITECTURAL_HYPERS.R_CUT,\n",
    "        ARCHITECTURAL_HYPERS.USE_ADDITIONAL_SCALAR_ATTRIBUTES,\n",
    "        ARCHITECTURAL_HYPERS.USE_LONG_RANGE,\n",
    "        ARCHITECTURAL_HYPERS.K_CUT,\n",
    "        ARCHITECTURAL_HYPERS.N_TARGETS > 1,\n",
    "        ARCHITECTURAL_HYPERS.N_TARGETS,\n",
    "    )\n",
    "    if ARCHITECTURAL_HYPERS.USE_LONG_RANGE:\n",
    "        raise NotImplementedError(\n",
    "            \"Long range interactions are not supported in the SingleStructCalculator\"\n",
    "        )\n",
    "\n",
    "    graph = molecule.get_graph(molecule.get_max_num(), all_species, None)\n",
    "    graph.batch = torch.zeros(graph.num_nodes, dtype=torch.long, device=graph.x.device)\n",
    "    graph = graph.to(device)\n",
    "    prediction_energy, prediction_forces = model(\n",
    "        graph, augmentation=False, create_graph=False\n",
    "    )\n",
    "\n",
    "    return prediction_energy, prediction_forces, graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (5x1 and 128x1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m model, structure, all_species, ARCHITECTURAL_HYPERS \u001b[38;5;241m=\u001b[39m prepare_test(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./example/methane_train.xyz\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m10.0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      5\u001b[0m graph \u001b[38;5;241m=\u001b[39m get_graph(structure, all_species, ARCHITECTURAL_HYPERS)\n\u001b[0;32m----> 7\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugmentation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# print(model.get_last_layer(graph, augmentation=False))\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# cpp_energy, cpp_forces, cpp_graph = get_predictions_cpp(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# print(\"Energy difference: \", torch.abs(python_energy - cpp_energy))\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# print(\"Forces difference: \", torch.abs(python_forces - cpp_forces).max())\u001b[39;00m\n",
      "File \u001b[0;32m~/pet-last-layer/src/pet.py:839\u001b[0m, in \u001b[0;36mPETMLIPWrapper.get_predictions\u001b[0;34m(self, batch, augmentation)\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_predictions\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, augmentation):\n\u001b[0;32m--> 839\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugmentation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugmentation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m predictions\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    842\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD_OUTPUT should be 1 for MLIP; energy is a single scalar\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/pet-last-layer/src/pet.py:821\u001b[0m, in \u001b[0;36mPETUtilityWrapper.forward\u001b[0;34m(self, batch, augmentation)\u001b[0m\n\u001b[1;32m    815\u001b[0m     indices \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mbatch\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    816\u001b[0m     rotations \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\n\u001b[1;32m    817\u001b[0m         get_rotations(indices, global_aug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_aug),\n\u001b[1;32m    818\u001b[0m         device\u001b[38;5;241m=\u001b[39mbatch\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[1;32m    819\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mbatch\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpet_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrotations\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/pet-last-layer/src/pet.py:800\u001b[0m, in \u001b[0;36mPET.forward\u001b[0;34m(self, batch_dict, rotations)\u001b[0m\n\u001b[1;32m    798\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 800\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pet-last-layer/src/pet.py:717\u001b[0m, in \u001b[0;36mPET.get_predictions\u001b[0;34m(self, batch_dict)\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcentral_token\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m result\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    714\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m central_tokens_predictor(\n\u001b[1;32m    715\u001b[0m         result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcentral_token\u001b[39m\u001b[38;5;124m\"\u001b[39m], central_species, target_indices\n\u001b[1;32m    716\u001b[0m     )\n\u001b[0;32m--> 717\u001b[0m     atomic_predictions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead_last_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_index\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m messages_predictor(\n\u001b[1;32m    720\u001b[0m         output_messages, mask, nums, central_species, multipliers, target_indices\n\u001b[1;32m    721\u001b[0m     )\n",
      "File \u001b[0;32m~/pet-last-layer/src/pet.py:434\u001b[0m, in \u001b[0;36mHeadLastLayer.forward\u001b[0;34m(self, hidden, target_indices)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden: torch\u001b[38;5;241m.\u001b[39mTensor, target_indices: Optional[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    433\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_targets \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 434\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124matomic_predictions\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m}\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m target_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget indices should be provided for multitarget fitting\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/pet-last-layer/src/pet.py:361\u001b[0m, in \u001b[0;36mFeedForwardLastLayer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/research/lib/python3.12/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (5x1 and 128x1)"
     ]
    }
   ],
   "source": [
    "model, structure, all_species, ARCHITECTURAL_HYPERS = prepare_test(\n",
    "    \"./example/methane_train.xyz\", 10.0, 2, 2\n",
    ")\n",
    "\n",
    "graph = get_graph(structure, all_species, ARCHITECTURAL_HYPERS)\n",
    "\n",
    "result = model.get_predictions(graph, augmentation=False)\n",
    "\n",
    "# print(model.get_last_layer(graph, augmentation=False))\n",
    "\n",
    "# cpp_energy, cpp_forces, cpp_graph = get_predictions_cpp(\n",
    "#     model, structure, all_species, ARCHITECTURAL_HYPERS\n",
    "# )\n",
    "\n",
    "# print(\"Energy difference: \", torch.abs(python_energy - cpp_energy))\n",
    "# print(\"Forces difference: \", torch.abs(python_forces - cpp_forces).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.6682], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph Data(x=[5, 4, 3], central_species=[5], neighbor_species=[5, 4], neighbors_pos=[5, 4], neighbors_index=[4, 5], nums=[5], mask=[5, 4], n_atoms=5, batch=[5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.6682], device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_energy, python_forces, python_graph = get_predictions_old_python(\n",
    "    model, structure, all_species, ARCHITECTURAL_HYPERS\n",
    ")\n",
    "python_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "PCA_X_reduced = pca.fit_transform(python_forces.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc7a675e090>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(PCA_X_reduced[:, 0], PCA_X_reduced[:, 1], s=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
